{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\nplotlosses = PlotLossesKeras()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1.Import libraries\nimport os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom pylab import rcParams\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nimport keras\n\nfrom keras.utils import np_utils\n\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import BatchNormalization,Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nprint(\"Tensorflow version:\", tf.__version__)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Set figure size\nrcParams['figure.figsize'] = 20, 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"2. #Import the dataset\n# data_path = '../input/effaj-dataset2/JAFFE_recompiled'\ndata_path = '../input/effaj-augmentation/JAFFE_recompiled'\ndata_dir_list = sorted(os.listdir(data_path))\ndata_dir_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows=256\nimg_cols=256\nnum_channel=1\n\nnum_epoch=10\n\nimg_data_list=[]\n\n\nfor dataset in data_dir_list:\n    img_list=os.listdir(data_path+'/'+ dataset)\n    print (f'Loaded the images of dataset {dataset}: {len(img_list)} images\\n')\n    for img in img_list:\n        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n#         print(len(img_list))\n        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n        input_img_resize=cv2.resize(input_img,(128,128))\n        img_data_list.append(input_img_resize)\n        \nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data = img_data/255\nimg_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3.Define the number of classes and attach class number\nnum_classes = 7\n\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')\n\nlabels[0:209]=0 #30 -> ANGRY\nlabels[210:410]=1 #29 -> DISGUSY\nlabels[411:633]=2 #32 -> FEAR\nlabels[634:850]=3 #31 -> NEUTRAL\nlabels[851:1059]=4 #30 -> HAPPY\nlabels[1060:1274]=5 #31 -> SAD\nlabels[1275:]=6 #30 -> SURPRISE\n\nnames = ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE']\n\ndef getLabel(id):\n    return ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE'][id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4.Convert the class label to one-hot encoding\nY = np_utils.to_categorical(labels, num_classes)\n\n#Shuffle the dataset\nx,y = shuffle(img_data,Y, random_state=2)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)\nx_test=X_test\nprint(f\"Train:{X_train.shape}\\nTest:{X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Build CNN layer\n# Defining the model\n\ninput_shape=(128,128,3)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(120, (5, 5), activation = 'relu'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(84, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation = 'softmax'))\n\n\n# Classification\n# model.add(Flatten())\n# model.add(Dense(64))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(num_classes))\n# model.add(Activation('softmax'))\n\n#Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5. Train model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau , EarlyStopping\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor = 0.01 , patience=10 , \n                             min_lr=0.00001 , mode='auto')\nearlystop = EarlyStopping(monitor ='val_loss',\n                         min_delta = 0, #abs value criteria for stopping\n                         patience = 2, #no of epochs to wait before stopping\n                         verbose = 1,\n                         restore_best_weights=True #keep the best weights once stopped\n                         )\nhist = model.fit(X_train, y_train, batch_size=7, epochs=50, verbose=1, validation_data=(X_test, y_test),callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}